{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F70i7bwAh3eT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iOY21r6iRH8"
      },
      "outputs": [],
      "source": [
        "### Loop the data lines\n",
        "with open(\"/content/news_text_25_5.csv\", 'r') as temp_f:\n",
        "    # get No of columns in each line\n",
        "    col_count = [ len(l.split(\",\")) for l in temp_f.readlines() ]\n",
        "\n",
        "### Generate column names  (names will be 0, 1, 2, ..., maximum columns - 1)\n",
        "# column_names = ['Link','Title', 'Date','Content']\n",
        "\n",
        "### Read csv\n",
        "df = pd.read_csv(\"/content/news_text_25_5.csv\", delimiter=\",\")\n",
        "# df.drop(index=df.index[0], axis=0, inplace=True)\n",
        "df = df.drop('Unnamed: 0', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37TVEBDr0cN3"
      },
      "outputs": [],
      "source": [
        "# dropna row\n",
        "# get a cell value\n",
        "index = 1\n",
        "col = \"text\"\n",
        "cell_val = df.iloc[index][col]\n",
        "print (\"Cell value at\", index, \"for column\", col, \":\", cell_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIuAX24P5vVS"
      },
      "outputs": [],
      "source": [
        "with open('test.txt', 'w') as f:\n",
        "  f.write(cell_val)\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pNjX-Ct0aNR"
      },
      "outputs": [],
      "source": [
        "!pip install pyvi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alHBkT260s9n"
      },
      "source": [
        "Hàm chuẩn hóa văn bản tiếng Việt với 5 bước\n",
        "- Chuẩn hóa unicode \n",
        "- Chuẩn hóa dấu câu tiếng Việt\n",
        "- Tách từ tiếng Việt\n",
        "- Chuyển chữ viết thường\n",
        "- Chuẩn hóa câu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOci7bWp0pEP"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import regex as re\n",
        "from pyvi import ViTokenizer, ViPosTagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31ug-J4v11Ru"
      },
      "outputs": [],
      "source": [
        "bang_nguyen_am= [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
        "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
        "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
        "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
        "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
        "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
        "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
        "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
        "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
        "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
        "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
        "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
        "\n",
        "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-_IosO32fgM"
      },
      "outputs": [],
      "source": [
        "nguyen_am_to_ids = {}\n",
        "for i in range(len(bang_nguyen_am)):\n",
        "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
        "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDxM7nyQ2ltb"
      },
      "source": [
        "Chuẩn hóa unicode\n",
        "\n",
        "Có 2 loại unicode : unicode tổ hơp và unicode dựng sẵn, điêu này dẫn tới việc 2 từ giống nhau sẽ bị coi là khác nhau \n",
        "\n",
        "Chuẩn hóa tất cả về 1 loại là unicode dựng sẵn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGiaZJ5F2q6c"
      },
      "outputs": [],
      "source": [
        "def chuan_hoa_unicode(text):\n",
        "\ttext = unicodedata.normalize('NFC', text)\n",
        "\treturn text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2xq536f2skU"
      },
      "source": [
        "Có 2 kiểu gõ dấu ở Tiếng Việt, ví dụ như là : òa hoặc oà (ta gọi lần lượt là chuẩn 1 và 2). Mặc dù kiểu gõ chữ sau ít phổ biến hơn tuy nhiên vẫn cần phải chuẩn hóa tránh việc một số văn bản vẫn sử dụng kiểu gõ dấu thứ 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_-NvEfd3C3M"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\tHàm này xử lý chuẩn hóa từng từ một, \n",
        "  sau khi chuẩn hóa từng từ thì sẽ chuân hóa từng câu sau \n",
        "\t\"\"\" \n",
        "def chuan_hoa_dau_tu_tieng_viet(word):\n",
        "    if not is_valid_vietnam_word(word):\n",
        "        return word\n",
        " \n",
        "    chars = list(word)\n",
        "    dau_cau = 0\n",
        "    nguyen_am_index = []\n",
        "    qu_or_gi = False\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x == -1:\n",
        "            continue\n",
        "        elif x == 9:  # check qu\n",
        "            if index != 0 and chars[index - 1] == 'q':\n",
        "                chars[index] = 'u'\n",
        "                qu_or_gi = True\n",
        "        elif x == 5:  # check gi\n",
        "            if index != 0 and chars[index - 1] == 'g':\n",
        "                chars[index] = 'i'\n",
        "                qu_or_gi = True\n",
        "        if y != 0:\n",
        "            dau_cau = y\n",
        "            chars[index] = bang_nguyen_am[x][0]\n",
        "        if not qu_or_gi or index != 1:\n",
        "            nguyen_am_index.append(index)\n",
        "    if len(nguyen_am_index) < 2:\n",
        "        if qu_or_gi:\n",
        "            if len(chars) == 2:\n",
        "                x, y = nguyen_am_to_ids.get(chars[1])\n",
        "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
        "            else:\n",
        "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
        "                if x != -1:\n",
        "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
        "                else:\n",
        "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
        "            return ''.join(chars)\n",
        "        return word\n",
        " \n",
        "    for index in nguyen_am_index:\n",
        "        x, y = nguyen_am_to_ids[chars[index]]\n",
        "        if x == 4 or x == 8:  # ê, ơ\n",
        "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
        "            # for index2 in nguyen_am_index:\n",
        "            #     if index2 != index:\n",
        "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
        "            #         chars[index2] = bang_nguyen_am[x][0]\n",
        "            return ''.join(chars)\n",
        " \n",
        "    if len(nguyen_am_index) == 2:\n",
        "        if nguyen_am_index[-1] == len(chars) - 1:\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
        "        else:\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "    else:\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
        "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
        "    return ''.join(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYDwIQos3Hsk"
      },
      "outputs": [],
      "source": [
        "def is_valid_vietnam_word(word):\n",
        "    chars = list(word)\n",
        "    nguyen_am_index = -1\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x != -1:\n",
        "            if nguyen_am_index == -1:\n",
        "                nguyen_am_index = index\n",
        "            else:\n",
        "                if index - nguyen_am_index != 1:\n",
        "                    return False\n",
        "                nguyen_am_index = index\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHQ-BroZ3JJU"
      },
      "outputs": [],
      "source": [
        "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
        "    \"\"\"\n",
        "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
        "        :param sentence:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "    sentence = sentence.lower()\n",
        "    words = sentence.split()\n",
        "    for index, word in enumerate(words):\n",
        "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
        "        # print(cw)\n",
        "        if len(cw) == 3:\n",
        "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
        "        words[index] = ''.join(cw)\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RPBQbjlJZ8L"
      },
      "source": [
        "Tách từ tiếng việt, từ tiếng việt không giống như tiếng anh, tách từ tiếng anh ta chỉ cần tách bằng khoảng trắng\n",
        "\n",
        "Tuy nhiên từ tiếng Việt có cả từ đơn lẫn từ ghép nên tách từ tiêng Việt sẽ phúc tạp hơn \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0UEQvGr3V10"
      },
      "outputs": [],
      "source": [
        "def tach_tu_tieng_viet(text):\n",
        "\ttext = ViTokenizer.tokenize(text)\n",
        "\treturn text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSmysVxu3ZuL"
      },
      "outputs": [],
      "source": [
        "# Đưa về chữ viết thường \n",
        "def chuyen_chu_thuong(text):\n",
        "\treturn text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRrRY0QI3cVj"
      },
      "outputs": [],
      "source": [
        "# Xóa đi các dấu cách thừa, các từ không cần thiết cho việc phân loại vẳn bản \n",
        "def chuan_hoa_cau(text):\n",
        "\ttext = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',text)\n",
        "\ttext = re.sub(r'\\s+', ' ', text).strip()\n",
        "\treturn text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAYc1G7B3eAU"
      },
      "outputs": [],
      "source": [
        "def tien_xu_li(text):\n",
        "\ttext = chuan_hoa_unicode(text)\n",
        "\ttext = chuan_hoa_dau_cau_tieng_viet(text)\n",
        "\ttext = tach_tu_tieng_viet(text)\n",
        "\ttext = chuyen_chu_thuong(text)\n",
        "\ttext = chuan_hoa_cau(text)\n",
        "\n",
        "\treturn text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G0BUqHc2A9d",
        "outputId": "ef02dc20-c7a1-429b-b5fa-adabf707aca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ví dụ : \n",
            "\n",
            "gặp_gỡ giảng_viên đại_học fpt giành huy_chương vàng tại giải muay thế_giới vượt qua hơn 3 000 vđv đến từ 112 quốc_gia và vùng lãnh_thổ thầy nguyễn văn yên giảng_viên bộ_môn vovinam tại đại_học fpt đã xuất_sắc mang về hai tấm huy_chương danh_giá cho đội_tuyển việt_nam ngày 125 tại giải_đấu ifma senior world được đăng_cai bởi liên_đoàn hiệp_hội muaythai quốc_tế giải_đấu quy_tụ sự tham_gia tranh tài của hơn 3 000 vđv đến từ 112 quốc_gia và vùng lãnh_thổ và được đăng_cai bởi ifma liên_đoàn hiệp_hội muaythai quốc_tế từ ngày 35 1352023 trên quê_hương của môn võ này tại xứ chùa vàng thầy nguyễn văn yên giảng_viên bộ_môn voivinam tại đại_học fpt đã xuất_sắc mang về huy_chương vàng nội_dung waikru đơn nam và huy_chương đồng_nội_dung maimuay đôi nam đây là niềm vinh_dự vào tự_hào không chỉ của trường đại_học fpt mà còn là của người dân việt_nam cùng lắng_nghe những chia_sẻ của thầy yên sau khi giải_đấu kết_thúc nhé xin chúc_mừng những thành_tích xuất_sắc của thầy tại giải_đấu ifma senior world championships 2023 điều này có ý_nghĩa như thế_nào với cá_nhân thầy hơn 11 năm thi_đấu thể_thao thành_đạt tích cao với 10 lần vô_địch quốc_gia và các thành_tích lớn nhỏ trong đối_kháng đây là lần đầu_tiên mình tham_dự nội_dung biểu_diễn waikru đơn nam ifma senior world championships 2023 là giải_đấu lớn nhất mình từng tham_dự và cũng là một giải_đấu thành_công nhất của mình ngoài giành được hai tấm huy_chương danh_giá thầy có kỉ_niệm đặc_biệt nào với mùa giải năm nay không vào vòng tuyển_chọn 16 nước mạnh nhất mình nhận thấy bản_thân có thế mạnh là sức_mạnh tốc_độ sự mềm_dẻo thần_thái và tác_phong tuy_nhiên sau khi công_bố kết_quả mình rất sock khi xếp ở vị_trí 1516 nước chính điều này là động_lực vô_cùng to_lớn để mình phải cố_gắng gấp nhiều lần sau vòng_đấu mình đã nghiên_cứu lại bài thi của các nước top đầu đặc_biệt là thailand cũng như trao_đổi lại với một_số chuyên_gia người thái lúc đó mới nhận ra đã thực_hiện sai một phần nội_dung trong thi_đấu ngay lập_tức_mình đã có sự điều_chỉnh tuy_nhiên thời_gian còn lại quá ngắn nên mình chỉ có_thể sửa được một_chút nhỏ ở vòng tiếp_theo số điểm mình đạt được đã được cải_thiện rất nhiều số với vòng trước từ 6 7 điểm và tới vòng này là 7 7 trong quá_trình tập_luyện cho vòng thi_đấu thầy có gặp phải khó_khăn gì không khó_khăn lớn nhất có_lẽ là quỹ thời_gian mình đi dạy ở đại_học fpt từ sáng tới 4h chiều sau đó lại gấp_rút luyện_tập tới 6h tối và tiếp_tục hoạt_động các clb võ của trường hôm nào sớm thì 9 10h tối mới về tới nhà thời_gian dành cho gia_đình cũng ít hơn về tới nhà thì con_gái đã đi ngủ sáng lại đi sớm lúc con còn chưa dậy đâu là bí_quyết giúp thầy thành_công tại mùa giải năm nay bí_quyết của mình đó là đặt mục_tiêu cho bản_thân tự_tin có_hậu_phương vững_chắc là đặc_biệt phải thật kiên_trì thầy đánh_giá về giải_đấu năm nay như thế_nào giải_đấu năm nay là một giải trọng_điểm nhằm kỷ_niệm 30 năm thành_lập liên_đoàn muay thai quốc_tế quy_mô cực lớn khi có hơn 100 nước tham_dự và có tới gần 3000 vđv tham_gia mình thực_sự choáng_ngợp trước sự hoành_tráng và chất_lượng của giải ngoài_ra để giành được huy_chương vàng này mình muốn gửi lời cảm_ơn rất lớn tới tất_cả mọi người cảm_ơn đội_tuyển việt_nam đội_tuyển muay công_an nhân_dân tổ_chức giáo_dục fpt các thầy cô ban huấn_luyện các đội_tuyển ngoài_ra còn có gia_đình và anh_em bạn_bè đã có sự hỗ_trợ động_viên về nhiều mặt để mình có_thể có được thành_công vừa_qua sau khi mùa giải kết_thúc thầy có đặt mục_tiêu gì khác không mục_tiêu và là định_hướng lâu_dài của mình trong tương_lai là phát_triển bản_thân phấn_đấu giành thêm nhiều thành_tích cống_hiến cho thể_thao việt_nam và cho tổ_chức giáo_dục fpt trước_mắt trong tháng 11 năm nay mình dự_kiến sẽ tham_gia giải vô_địch châu á với nội_dung boran biểu_diễn muaythai xin chúc_mừng thầy nguyễn văn yên và đoàn việt_nam đã có những thành_tích_cực_kỳ ấn_tượng trong giải_đấu mong rằng thầy và toàn đội_tuyển sẽ luôn giữ vững phong_độ phát_huy hết khả_năng và gặt_hái được nhiều thành_công hơn nữa\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    file = open(\"test.txt\", \"r\", encoding=\"utf-8\")\n",
        "    data = file.read()\n",
        "    data = tien_xu_li(data)\n",
        "    print(\"Ví dụ : \\n\")\n",
        "    print(data)\n",
        "    with open('final.txt', 'w') as f:\n",
        "      f.write(data)\n",
        "      f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqNarDOh0iSd"
      },
      "outputs": [],
      "source": [
        "#read input file\n",
        "f = open(\"final.txt\", \"rt\")\n",
        "#read file contents to string\n",
        "data = f.read()\n",
        "#replace all occurrences of the required string\n",
        "data = data.replace('_', ' ')\n",
        "#close the input file\n",
        "f.close()\n",
        "#open the input file in write mode\n",
        "f = open(\"final.txt\", \"wt\")\n",
        "#overrite the input file with the resulting data\n",
        "f.write(data)\n",
        "#close the file\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05ZjiPEnGQBh"
      },
      "source": [
        "Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qIzVWVwGO-q"
      },
      "outputs": [],
      "source": [
        "stopwords = open('stopword.txt', 'r')\n",
        "stopwords_list = stopwords.read().split('\\n')\n",
        "final = open('final.txt', 'r')\n",
        "final = final.read().split()\n",
        "res = []\n",
        "for word in final:\n",
        "  if word not in stopwords_list:\n",
        "    res.append(word)\n",
        "\n",
        "res"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.16 ('namph')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "f3956098809fbecdb0cd9151aa3d96b93ad3c7565181a3f5ad9a456aaf113d5a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
